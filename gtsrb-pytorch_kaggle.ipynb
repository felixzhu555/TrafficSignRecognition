{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nimport numpy as np\nimport pandas as pd\nimport os\nimport cv2\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:42:59.017861Z","iopub.execute_input":"2022-09-02T05:42:59.018253Z","iopub.status.idle":"2022-09-02T05:42:59.025935Z","shell.execute_reply.started":"2022-09-02T05:42:59.018221Z","shell.execute_reply":"2022-09-02T05:42:59.024642Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# # Download training data from open datasets.\n# training_data = datasets.GTSRB(\n#     root=\"data\",\n#     split=\"train\",\n#     download=True,\n#     transform=ToTensor(),\n# )\n\n# # Download test data from open datasets.\n# test_data = datasets.GTSRB(\n#     root=\"data\",\n#     split=\"test\",\n#     download=True,\n#     transform=ToTensor(),\n# )\n# type(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:42:59.028358Z","iopub.execute_input":"2022-09-02T05:42:59.029049Z","iopub.status.idle":"2022-09-02T05:42:59.037186Z","shell.execute_reply.started":"2022-09-02T05:42:59.029012Z","shell.execute_reply":"2022-09-02T05:42:59.036109Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"def zero_extend(n):\n    if type(n) is not int:\n        print(\"error in zero_extend\")\n        return\n    elif n < 10:\n        return \"0000\" + str(n)\n    else:\n        return \"000\" + str(n)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:42:59.038760Z","iopub.execute_input":"2022-09-02T05:42:59.039115Z","iopub.status.idle":"2022-09-02T05:42:59.047498Z","shell.execute_reply.started":"2022-09-02T05:42:59.039081Z","shell.execute_reply":"2022-09-02T05:42:59.046617Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"train_dir = '../input/german-traffic-sign-recognition/GTSRB_training/Training'\n\nchannels = 3\nIMG_HEIGHT = 30\nIMG_WIDTH = 30\nNUM_CLASSES = len(os.listdir(train_dir))\n\nimage_data = []\nimage_labels = []\n\n# Resize images to 30x30\nfor i in range(NUM_CLASSES):\n    path = train_dir + '/' + zero_extend(i)\n    images = os.listdir(path)\n    print(path)\n\n    for img in images:\n        if img[0:2] == \"GT\":\n            continue\n        image = cv2.imread(path + '/' + img)\n        image_fromarray = Image.fromarray(image, 'RGB')\n        resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n        reshape_image_arr = np.reshape(np.array(resize_image), (3, 30, 30))\n        image_data.append(reshape_image_arr)\n        image_labels.append(i)\n\n# Changing the list to numpy array\nimage_data = np.array(image_data)\nimage_labels = np.array(image_labels)\n\nprint(image_data.shape, image_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:42:59.049917Z","iopub.execute_input":"2022-09-02T05:42:59.050518Z","iopub.status.idle":"2022-09-02T05:43:23.774928Z","shell.execute_reply.started":"2022-09-02T05:42:59.050483Z","shell.execute_reply":"2022-09-02T05:43:23.773837Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# shuffle dataset\nshuffle_indexes = np.arange(image_data.shape[0])\nnp.random.shuffle(shuffle_indexes)\nimage_data = image_data[shuffle_indexes]\nimage_labels = image_labels[shuffle_indexes]","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:23.776190Z","iopub.execute_input":"2022-09-02T05:43:23.777566Z","iopub.status.idle":"2022-09-02T05:43:23.809000Z","shell.execute_reply.started":"2022-09-02T05:43:23.777526Z","shell.execute_reply":"2022-09-02T05:43:23.807927Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# split train data into training (80%) and validation (20%)\nX_train, X_val, y_train, y_val = train_test_split(\n    image_data, image_labels, test_size=0.2, random_state=42, shuffle=True)\n\n\n# X_train = X_train/255 \n# X_val = X_val/255\n\nprint(\"X_train.shape\", X_train.shape)\nprint(\"X_valid.shape\", X_val.shape)\nprint(\"y_train.shape\", y_train.shape)\nprint(\"y_valid.shape\", y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:23.811149Z","iopub.execute_input":"2022-09-02T05:43:23.811987Z","iopub.status.idle":"2022-09-02T05:43:23.845888Z","shell.execute_reply.started":"2022-09-02T05:43:23.811928Z","shell.execute_reply":"2022-09-02T05:43:23.844847Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# construct dataloader for pytorch usage\nbatch_size = 64\n\ntensor_x_train = torch.Tensor(X_train) # transform to torch tensor\ntensor_y_train = torch.Tensor(y_train).long()\ntensor_x_val = torch.Tensor(X_val)\ntensor_y_val = torch.Tensor(y_val).long()\n\ntraining_data = TensorDataset(tensor_x_train,tensor_y_train)\nval_data = TensorDataset(tensor_x_val,tensor_y_val)\n\n# Create data loaders.\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size)\nval_dataloader = DataLoader(val_data, batch_size=batch_size) # do we need a loader for validation?\n\nfor X, y in train_dataloader:\n    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n    print(f\"Shape of y: {y.shape} {y.dtype}\")\n    break","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:23.847364Z","iopub.execute_input":"2022-09-02T05:43:23.848018Z","iopub.status.idle":"2022-09-02T05:43:24.103201Z","shell.execute_reply.started":"2022-09-02T05:43:23.847974Z","shell.execute_reply":"2022-09-02T05:43:24.102093Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# Define model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(2700, 1300),\n            nn.ReLU(),\n            nn.Linear(1300, 600),\n            nn.ReLU(),\n            nn.Linear(600, 300),\n            nn.ReLU(),\n            nn.Linear(300, 150),\n            nn.ReLU(),\n            nn.Linear(150, 43)\n        )\n\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n\n    \nclass ConvNN(nn.Module):\n    def __init__(self):\n        super(ConvNN, self).__init__()\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, 3),\n            nn.ReLU(),\n            nn.Conv2d(16, 32, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.BatchNorm2d(32),\n            nn.Dropout(p=0.5)\n        )\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(32, 64, 3),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 3),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2),\n            nn.BatchNorm2d(128),\n            nn.Dropout(p=0.5)\n        )\n        self.flatten = nn.Flatten()\n        self.lin1 = nn.Linear(2048, 512)\n        self.lin2 = nn.Linear(512, 43)\n#         nn.init.xavier_uniform_(self.lin1.weight)\n#         nn.init.xavier_uniform_(self.lin2.weight)\n        self.layer3 = nn.Sequential(\n            self.lin1,\n            nn.ReLU(),\n            nn.Dropout(p=0.5),\n            self.lin2\n        )\n        \n    def forward(self, x):\n        out = self.layer1(x)\n#         print(out.size())\n        out = self.layer2(out)\n#         print(out.size())\n        out = self.flatten(out)\n        out = self.layer3(out)\n        return out\n        \n\nmodel = ConvNN().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:24.106631Z","iopub.execute_input":"2022-09-02T05:43:24.106932Z","iopub.status.idle":"2022-09-02T05:43:24.136751Z","shell.execute_reply.started":"2022-09-02T05:43:24.106905Z","shell.execute_reply":"2022-09-02T05:43:24.135758Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), \n                            lr=1e-3,\n                            weight_decay=0.001\n                           )","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:24.138199Z","iopub.execute_input":"2022-09-02T05:43:24.138581Z","iopub.status.idle":"2022-09-02T05:43:24.143953Z","shell.execute_reply.started":"2022-09-02T05:43:24.138545Z","shell.execute_reply":"2022-09-02T05:43:24.142736Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"#from torch import autograd\ndef train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    model.train()\n    for batch, (X, y) in enumerate(dataloader):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X)\n        loss = loss_fn(pred, y)\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:24.145857Z","iopub.execute_input":"2022-09-02T05:43:24.146272Z","iopub.status.idle":"2022-09-02T05:43:24.156435Z","shell.execute_reply.started":"2022-09-02T05:43:24.146239Z","shell.execute_reply":"2022-09-02T05:43:24.155471Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"def test_val(dataloader, model, loss_fn):\n    size = len(dataloader.dataset)\n    num_batches = len(dataloader)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            test_loss += loss_fn(pred, y).item()\n            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n    test_loss /= num_batches\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:24.157621Z","iopub.execute_input":"2022-09-02T05:43:24.159812Z","iopub.status.idle":"2022-09-02T05:43:24.167972Z","shell.execute_reply.started":"2022-09-02T05:43:24.159785Z","shell.execute_reply":"2022-09-02T05:43:24.167130Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"epochs = 40\nfor t in range(epochs):\n    print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_dataloader, model, loss_fn, optimizer)\n    test_val(val_dataloader, model, loss_fn)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:43:24.170799Z","iopub.execute_input":"2022-09-02T05:43:24.171076Z","iopub.status.idle":"2022-09-02T05:44:32.077706Z","shell.execute_reply.started":"2022-09-02T05:43:24.171051Z","shell.execute_reply":"2022-09-02T05:44:32.075959Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# get testing data\ntest_dir = '../input/german-traffic-sign-recognition/GTSRB_testing/Images'\ntest_csv = pd.read_csv('../input/german-traffic-sign-recognition/GT-final_test.csv', sep=';')\n\nlabels = test_csv[\"ClassId\"].values\nimgs = test_csv[\"Filename\"].values\n\ntest_data = []\nfor img in imgs:\n    image = cv2.imread(test_dir + '/' + img)\n    image_fromarray = Image.fromarray(image, 'RGB')\n    resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n    reshape_image_arr = np.reshape(np.array(resize_image), (3, 30, 30))\n    test_data.append(reshape_image_arr)\n\nlen(test_data)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:44:32.079212Z","iopub.execute_input":"2022-09-02T05:44:32.079801Z","iopub.status.idle":"2022-09-02T05:44:43.447364Z","shell.execute_reply.started":"2022-09-02T05:44:32.079762Z","shell.execute_reply":"2022-09-02T05:44:43.446283Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# final testing\nX_test = np.array(test_data)\ntensor_X_test = torch.Tensor(X_test)\ntensor_X_test = tensor_X_test.cuda()\nwith torch.no_grad():\n    pred = model(tensor_X_test)\n\npred_classes = pred.argmax(1)\npred_classes = pred_classes.to('cpu')\nprint('Test Data accuracy: ', accuracy_score(labels, pred_classes)*100)","metadata":{"execution":{"iopub.status.busy":"2022-09-02T05:44:43.448890Z","iopub.execute_input":"2022-09-02T05:44:43.449513Z","iopub.status.idle":"2022-09-02T05:44:43.722475Z","shell.execute_reply.started":"2022-09-02T05:44:43.449476Z","shell.execute_reply":"2022-09-02T05:44:43.721480Z"},"trusted":true},"execution_count":98,"outputs":[]}]}